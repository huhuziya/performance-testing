压测数据分析
========
### 压测报告表格
|场景|请求数Sample|Average|Median|90% Line|95% Line|99% Line|Min|Max|Error%|Throughput|Received KB/Sec|Sent KB/Sec|CPU|RPS|
|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|
|10线程运行5分钟|241423|11|11|14|17|22|8|1602|0.00%|804.7/sec|1328.047032|216.1075094|<35%|804/s|
|30线程运行5分钟|215449|39|39|45|47|56|8|1252|0.00%|718.1/sec|1185.178189|192.8532727|<35%|718/s|
|50线程运行5分钟|187002|79|78|98|105|122|8|290|0.00%|623.3/sec|1028.637913|167.381909|<35%|623/s|
1. TPS=804，CPU使用均低于35%  
2. 当并发10时，tps约为804，95%的响应时间在17ms以内，增加并发，运行时间不变时总请求量呈下降趋势，TPS也呈下降趋势，响应时间增长  
3. 压测过程中，内存呈现平稳状态，网络I/O、CPU状态、磁盘读写呈现异常，需排查
### 技术指标
Average ：每个请求的平均响应时间  
Median ：中值，即50%请求的平均响应时间  
90%Line ：90%请求的响应时间  
95%Line ：95%请求的响应时间  
99%Line ：99%请求的响应时间  
Min ：最小响应时间   
Max ：最大的响应时间  
Error% ：错误响应的概率。即无法响应的概率。  
ThroughPut ：吞吐量， 默认情况下表示每秒完成的请求数（Request per Second），可用{总请求量}/{运行时间} 计算    
```buildoutcfg
吞吐量的指标受到响应时间、服务器软硬件配置、网络状态等多方面因素影响。
- 吞吐量越大，响应时间越长。
- 服务器硬件配置越高，吞吐量越大。
- 网络越差，吞吐量越小。
```
Received KB/Sec ：客户端每秒从服务器端接收到的数据量  
Sent KB/Sec ：客户端每秒发送给服务器端的数据量  

- RPS：即Requests Per Second的缩写，每秒能处理的请求数目。等效于QPS
- QPS：即Queries Per Second的缩写，每秒能处理查询数目
- TPS：即Transactions Per Second的缩写，每秒处理的事务数目
- RT：即Response-time，响应时间，一般取平均响应时间
- 并发数：系统同时处理的request/事务数，类似概念需要区分并发用户数与TPS，秒并发，系统用户数，在线用户数等的区别

计算公式：  
QPS（TPS）= 并发数/平均响应时间
并发数 = QPS*平均响应时间

1. cpu逻辑计算
2. 内存memory读取数据
3. 磁盘I/O存储数据
- 响应时间  
举例：一个页面会发出5次请求，那么这5次请求均落在P90以内概率是90%^5=59%，至少会经历一次 > P90响应时间的概率是 100%-59%=41%，如果你的P90=10s，那么就意味着用户有41%的概率会在加载页面的时候超过10s  
如果你的P99=10s，那么用户只有5%的概率会在访问页面的时候超过10s。如果P99.9=10s，则有0.4%的概率

### 系统资源耗用
[参考链接](https://www.jianshu.com/p/9f5d10f5e938)
- CPU使用率
1）当CPU使用率超过80%时，表明CPU应用繁忙，如果持续维持在90%甚至更高，很可能导致机器响应慢、死机等问题
2）当CPU使用率过低时，说明CPU比较空闲，可能存在资源浪费的问题  

- 内存使用率  
对于内存，同样存在类似以上的问题

- “258原则”-响应时间参考值  
1）当用户能够在2s以内得到响应时，会感觉系统的响应很快  
2）当用户在2-5s内得到响应时，会感觉系统的响应速度还可以  
3）当用户在5-8s内得到响应时，会感觉系统的响应速度很慢，但还可以接受  
4）当用户在超过8s后仍然无法得到响应时，会感觉系统糟透了，or认为系统已经失去响应，而选择离开这个Web站点，or发起第二次请求  


> 小Tips：当内存不足时需要跟磁盘进行页(page)交换,从而产生磁盘IO


### 性能瓶颈
- 硬件上的性能瓶颈：  
一般指的是CPU、内存、磁盘I/O 方面的问题，分为服务器硬件瓶颈、网络瓶颈（对局域网可以不考虑）、服务器操作系统瓶颈（参数配置）、中间件瓶颈（参数配置、数据库、web服务器等）、应用瓶颈（SQL 语句、数据库设计、业务逻辑、算法等）。

- 应用软件上的性能瓶颈：  
一般指的是应用服务器、web 服务器等应用软件，还包括数据库系统。  
例如：中间件weblogic 平台上配置的JDBC连接池的参数设置不合理，造成的瓶颈。

- 应用程序上的性能瓶颈：  
一般指的是开发人员新开发出来的应用程序。  
例如，程序架构规划不合理，程序本身设计有问题（串行处理、请求的处理线程不够），造成系统在大量用户方位时性能低下而造成的瓶颈。

- 操作系统上的性能瓶颈：  
一般指的是windows、UNIX、Linux等操作系统。  
例如，在进行性能测试，出现物理内存不足时，虚拟内存设置也不合理，虚拟内存的交换效率就会大大降低，从而导致行为的响应时间大大增加，这时认为操作系统上出现性能瓶颈。

- 网络设备上的性能瓶颈：  
一般指的是防火墙、动态负载均衡器、交换机等设备。  
例如，在动态负载均衡器上设置了动态分发负载的机制，当发现某个应用服务器上的硬件资源已经到达极限时，动态负载均衡器将后续的交易请求发送到其他负载较轻的应用服务器上。在测试时发现，动态负载均衡器没有起到相应的作用，这时可以认为网络瓶颈。